{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## automl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {},
      "source": [
        "blob_account_name = \"azureopendatastorage\"\n",
        "blob_container_name = \"nyctlc\"\n",
        "blob_relative_path = \"yellow\"\n",
        "blob_sas_token = r\"\"\n",
        "\n",
        "# Allow Spark to read from Blob remotely\n",
        "wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\n",
        "spark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),blob_sas_token)\n",
        "\n",
        "# Spark read parquet, note that it won't load any data yet by now\n",
        "df = spark.read.parquet(wasbs_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Create an ingestion filter to take a look at one month\n",
        "start_date = '2017-01-07 00:00:00'\n",
        "end_date = '2017-01-08 00:00:00'\n",
        "\n",
        "filtered_df = df.filter('tpepPickupDateTime > \"' + start_date + '\" and tpepPickupDateTime < \"' + end_date + '\"')\n",
        "\n",
        "filtered_df.describe().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from datetime import datetime\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# To make development easier, faster and less expensive down sample for now\n",
        "sampled_taxi_df = filtered_df.sample(True, 0.001, seed=1234)\n",
        "\n",
        "taxi_df = sampled_taxi_df.select('vendorID', 'passengerCount', 'tripDistance',  'startLon', 'startLat', 'endLon' \\\n",
        "                                , 'endLat', 'paymentType', 'fareAmount', 'tipAmount'\\\n",
        "                                , column('puMonth').alias('month_num') \\\n",
        "                                , date_format('tpepPickupDateTime', 'hh').alias('hour_of_day')\\\n",
        "                                , date_format('tpepPickupDateTime', 'EEEE').alias('day_of_week')\\\n",
        "                                , dayofmonth(col('tpepPickupDateTime')).alias('day_of_month')\n",
        "                                ,(unix_timestamp(col('tpepDropoffDateTime')) - unix_timestamp(col('tpepPickupDateTime'))).alias('trip_time'))\\\n",
        "                        .filter((sampled_taxi_df.passengerCount > 0) & (sampled_taxi_df.passengerCount < 8)\\\n",
        "                                & (sampled_taxi_df.tipAmount >= 0)\\\n",
        "                                & (sampled_taxi_df.fareAmount >= 1) & (sampled_taxi_df.fareAmount <= 250)\\\n",
        "                                & (sampled_taxi_df.tipAmount < sampled_taxi_df.fareAmount)\\\n",
        "                                & (sampled_taxi_df.tripDistance > 0) & (sampled_taxi_df.tripDistance <= 200)\\\n",
        "                                & (sampled_taxi_df.rateCodeId <= 5)\\\n",
        "                                & (sampled_taxi_df.paymentType.isin({\"1\", \"2\"})))\n",
        "taxi_df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Random split dataset using spark\n",
        "training_data, validation_data = taxi_df.randomSplit([0.8,0.2], 223)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "# Enter your workspace subscription, resource group, name, and region.\n",
        "subscription_id = \"8736b1ec-0ab5-460e-8c92-9edffbaffad5\" #you should be owner or contributor\n",
        "resource_group = \"MLResources\" #you should be owner or contributor\n",
        "workspace_name = \"azureML\" #your workspace name\n",
        "workspace_region = \"WestUS2\" #your region\n",
        "\n",
        "ws = Workspace(workspace_name = workspace_name,\n",
        "               subscription_id = subscription_id,\n",
        "               resource_group = resource_group)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "#create a Aml Tabular dataset from a pandas dataframe\n",
        "import pandas \n",
        "from azureml.core import Dataset\n",
        "\n",
        "# Get the AML Default Datastore\n",
        "datastore = ws.get_default_datastore()\n",
        "training_pd = training_data.toPandas().to_csv('training_pd.csv', index=False)\n",
        "\n",
        "# Convert into AML Tabular Dataset\n",
        "datastore.upload_files(files = ['training_pd.csv'],\n",
        "                       target_path = 'train-dataset/tabular/',\n",
        "                       overwrite = True,\n",
        "                       show_progress = True)\n",
        "dataset_training = Dataset.Tabular.from_delimited_files(path = [(datastore, 'train-dataset/tabular/training_pd.csv')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "import logging\n",
        "\n",
        "automl_settings = {\n",
        "      \"experiment_timeout_minutes\": 30,\n",
        "    \"enable_early_stopping\" : True,\n",
        "    \"iteration_timeout_minutes\": 5,\n",
        "    \"max_concurrent_iterations\": 4,\n",
        "    \"max_cores_per_iteration\": -1,\n",
        "    \"primary_metric\": 'r2_score',\n",
        "    \"featurization\": 'auto',\n",
        "    \"verbosity\": logging.INFO,\n",
        "    \"n_cross_validations\": 2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "automl_config = AutoMLConfig(task='regression',\n",
        "                             debug_log='automated_ml_errors.log',\n",
        "                             training_data = dataset_training,\n",
        "                             spark_context = sc,\n",
        "                             model_explainability = False, \n",
        "                             label_column_name =\"fareAmount\",**automl_settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from azureml.core.experiment import Experiment\n",
        "\n",
        "# Start an experiment in Azure Machine Learning\n",
        "experiment = Experiment(ws, \"aml-synapse-regression\")\n",
        "tags = {\"Synapse\": \"regression\"}\n",
        "local_run = experiment.submit(automl_config, show_output=True, tags = tags)\n",
        "\n",
        "# Use the get_details function to retrieve the detailed output for the run.\n",
        "run_details = local_run.get_details()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Get best model\n",
        "best_run, fitted_model = local_run.get_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Test best model accuracy\n",
        "validation_data_pd = validation_data.toPandas()\n",
        "y_test = validation_data_pd.pop(\"fareAmount\").to_frame()\n",
        "y_predict = fitted_model.predict(validation_data_pd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Calculate Root Mean Square Error\n",
        "y_actual = y_test.values.flatten().tolist()\n",
        "rmse = sqrt(mean_squared_error(y_actual, y_predict))\n",
        "\n",
        "print(\"Root Mean Square Error:\")\n",
        "print(rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Calculate MAPE and Model Accuracy \n",
        "sum_actuals = sum_errors = 0\n",
        "\n",
        "for actual_val, predict_val in zip(y_actual, y_predict):\n",
        "    abs_error = actual_val - predict_val\n",
        "    if abs_error < 0:\n",
        "        abs_error = abs_error * -1\n",
        "\n",
        "    sum_errors = sum_errors + abs_error\n",
        "    sum_actuals = sum_actuals + actual_val\n",
        "\n",
        "mean_abs_percent_error = sum_errors / sum_actuals\n",
        "\n",
        "print(\"Model MAPE:\")\n",
        "print(mean_abs_percent_error)\n",
        "print()\n",
        "print(\"Model Accuracy:\")\n",
        "print(1 - mean_abs_percent_error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Calculate the R2 score using the predicted and actual fare prices\n",
        "y_test_actual = y_test[\"fareAmount\"]\n",
        "r2 = r2_score(y_test_actual, y_predict)\n",
        "\n",
        "# Plot the Actual vs Predicted Fare Amount Values\n",
        "plt.style.use('ggplot')\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(y_test_actual,y_predict)\n",
        "plt.plot([np.min(y_test_actual), np.max(y_test_actual)], [np.min(y_test_actual), np.max(y_test_actual)], color='lightblue')\n",
        "plt.xlabel(\"Actual Fare Amount\")\n",
        "plt.ylabel(\"Predicted Fare Amount\")\n",
        "plt.title(\"Actual vs Predicted Fare Amont R^2={}\".format(r2))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "description = 'Tip Prediction Model'\n",
        "model_path='outputs/model.pkl'\n",
        "model = best_run.register_model(model_name = 'NYCGreenTaxiModel', model_path = model_path, description = description)\n",
        "print(model.name, model.version)"
      ]
    }
  ]
}